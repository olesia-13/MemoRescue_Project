from dotenv import load_dotenv
import cv2
import mediapipe as mp
import numpy as np
import json
import os
import requests
import time
from collections import deque
from scipy.spatial.distance import cosine

load_dotenv()

# Ğ’ĞºĞ°Ğ¶Ñ–Ñ‚ÑŒ Ñ‚Ğ¾Ñ‡Ğ½Ñ– ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ğ¸ Ğ¼Ñ–ÑÑ†Ñ Ğ²ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ ĞºĞ°Ğ¼ĞµÑ€Ğ¸
CAMERA_LAT = 50.5186  
CAMERA_LON = 30.2397

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

# â”€â”€ Ğ—ĞĞ“ĞĞ›Ğ¬ĞĞ† ĞĞĞ›ĞĞ¨Ğ¢Ğ£Ğ’ĞĞĞĞ¯ Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATABASE_DIR = os.path.join(os.path.dirname(__file__), "database")
SIMILARITY_THRESHOLD = 0.85     
QUEUE_SIZE = 100                

ZIGZAG_WINDOW = 60              
ZIGZAG_SINUOSITY = 2.5          
STILLNESS_FRAMES = 90           
STILLNESS_VEL_THRESH = 0.003    

IDENTIFY_EVERY = 30             
ALERT_COOLDOWN = 60             
ANOMALY_CONFIRM_TIME = 2.0      # Ğ§Ğ°Ñ Ğ´Ğ»Ñ Ğ¿Ñ–Ğ´Ñ‚Ğ²ĞµÑ€Ğ´Ğ¶ĞµĞ½Ğ½Ñ Ñ‚Ñ€Ğ¸Ğ²Ğ¾Ğ³Ğ¸

if TELEGRAM_BOT_TOKEN is None:
    print("[ERROR] Ğ¢Ğ¾ĞºĞµĞ½ Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾! ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ñ‚Ğµ Ñ„Ğ°Ğ¹Ğ» .env")
else:
    print(f"[INFO] Ğ¢Ğ¾ĞºĞµĞ½ ÑƒÑĞ¿Ñ–ÑˆĞ½Ğ¾ Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ¾: {TELEGRAM_BOT_TOKEN[:10]}...")
    
# Ğ¡Ğ»Ğ¾Ğ²Ğ½Ğ¸ĞºĞ¸ ÑÑ‚Ğ°Ğ½Ñƒ
last_alerts = {}
anomaly_start_time = None       

# â”€â”€ MEDIAPIPE Ğ†ĞĞ†Ğ¦Ğ†ĞĞ›Ğ†Ğ—ĞĞ¦Ğ†Ğ¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
pose = mp_pose.Pose(
    static_image_mode=False,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

# â”€â”€ Ğ¤Ğ£ĞĞšĞ¦Ğ†Ğ¯ TELEGRAM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def send_telegram_alert(user_name, phone, chat_id, alert_type):
    """ĞĞ°Ğ´ÑĞ¸Ğ»Ğ°Ñ” ÑĞ¿Ğ¾Ğ²Ñ–Ñ‰ĞµĞ½Ğ½Ñ Ğ· ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ğ°Ğ¼Ğ¸ ĞºĞ°Ğ¼ĞµÑ€Ğ¸ Ñ‚Ğ° Ğ¿Ğ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½ÑĞ¼ Ğ½Ğ° ĞºĞ°Ñ€Ñ‚Ñƒ."""
    if not chat_id:
        print(f"[WARN] Chat ID Ğ´Ğ»Ñ {user_name} Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾.")
        return

    # Ğ¤Ğ¾Ñ€Ğ¼ÑƒÑ”Ğ¼Ğ¾ Ğ¿Ğ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ Ğ½Ğ° Google Maps
    maps_link = f"https://www.google.com/maps?q={49.8441550958368},{24.026250638148717}"
    
    emoji = "ğŸš¨" if alert_type == "ZIGZAG" else "âš ï¸"
    message = (
        f"{emoji} MemoRescue: ĞŸĞ†Ğ”Ğ¢Ğ’Ğ•Ğ Ğ”Ğ–Ğ•ĞĞ Ğ¢Ğ Ğ˜Ğ’ĞĞ“Ğ£!!!\n"
        f"----------------------------------\n"
        f"ğŸ‘¤ ĞÑĞ¾Ğ±Ğ°: {user_name}\n"
        f"ğŸ”— ĞšĞ°Ñ€Ñ‚Ğ°: {maps_link}\n"
        f"â° Ğ§Ğ°Ñ: {time.strftime('%H:%M:%S')}"
    )
    
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    try:
        payload = {"chat_id": chat_id, "text": message}
        requests.post(url, data=payload)
        print(f"[SUCCESS] Ğ¢Ñ€Ğ¸Ğ²Ğ¾Ğ³Ñƒ Ğ· Ğ³ĞµĞ¾Ğ»Ğ¾ĞºĞ°Ñ†Ñ–Ñ”Ñ Ğ½Ğ°Ğ´Ñ–ÑĞ»Ğ°Ğ½Ğ¾ Ğ´Ğ»Ñ {user_name}")
    except Exception as e:
        print(f"[ERROR] ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ½Ğ°Ğ´Ñ–ÑĞ»Ğ°Ñ‚Ğ¸ Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ½Ñ: {e}")

# â”€â”€ Ğ”ĞĞŸĞĞœĞ†Ğ–ĞĞ† Ğ¤Ğ£ĞĞšĞ¦Ğ†Ğ‡ ĞĞĞĞ›Ğ†Ğ—Ğ£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _angle(a, b, c):
    va = np.array([a.x - b.x, a.y - b.y])
    vc = np.array([c.x - b.x, c.y - b.y])
    n_a, n_c = np.linalg.norm(va), np.linalg.norm(vc)
    if n_a < 1e-6 or n_c < 1e-6: return 0.0
    return float(np.arccos(np.clip(np.dot(va, vc) / (n_a * n_c), -1.0, 1.0)))

def extract_features(landmarks):
    try:
        lm = landmarks
        nose = lm[mp_pose.PoseLandmark.NOSE]
        l_an, r_an = lm[mp_pose.PoseLandmark.LEFT_ANKLE], lm[mp_pose.PoseLandmark.RIGHT_ANKLE]
        l_hip, r_hip = lm[mp_pose.PoseLandmark.LEFT_HIP], lm[mp_pose.PoseLandmark.RIGHT_HIP]
        l_kn, r_kn = lm[mp_pose.PoseLandmark.LEFT_KNEE], lm[mp_pose.PoseLandmark.RIGHT_KNEE]
        l_sh, r_sh = lm[mp_pose.PoseLandmark.LEFT_SHOULDER], lm[mp_pose.PoseLandmark.RIGHT_SHOULDER]
        h = abs(nose.y - l_an.y)
        if h < 0.01: return None
        return [np.sqrt((l_an.x-r_an.x)**2+(l_an.y-r_an.y)**2)/h, _angle(l_hip,l_kn,l_an), _angle(r_hip,r_kn,r_an),
                _angle(l_sh,l_hip,l_kn), _angle(r_sh,r_hip,r_kn), np.sqrt((l_sh.x-r_sh.x)**2+(l_sh.y-r_sh.y)**2)/h, abs(l_an.y-r_an.y)/h]
    except: return None

def load_database():
    users = []
    if not os.path.exists(DATABASE_DIR): return users
    for fn in os.listdir(DATABASE_DIR):
        if fn.endswith(".json"):
            with open(os.path.join(DATABASE_DIR, fn), "r", encoding="utf-8") as f:
                users.append(json.load(f))
    return users

def identify_person(current_vec, users):
    best_u, best_s = None, -1.0
    curr = np.array(current_vec).flatten()
    for u in users:
        sig = np.array(u["gait_signature"]).flatten()
        if curr.shape == sig.shape:
            sim = 1.0 - cosine(curr, sig)
            if sim > best_s: best_s, best_u = sim, u
    return (best_u, best_s) if best_s >= SIMILARITY_THRESHOLD else (None, best_s)

def detect_zigzag(positions):
    if len(positions) < ZIGZAG_WINDOW: return False
    pts = list(positions)[-ZIGZAG_WINDOW:]
    disp = np.linalg.norm(pts[-1] - pts[0])
    if disp < 0.01: return False
    path = sum(np.linalg.norm(pts[i]-pts[i-1]) for i in range(1, len(pts)))
    return (path / disp) > ZIGZAG_SINUOSITY

def detect_stillness(positions):
    if len(positions) < STILLNESS_FRAMES: return False
    pts = list(positions)[-STILLNESS_FRAMES:]
    return all(np.linalg.norm(pts[i]-pts[i-1]) < STILLNESS_VEL_THRESH for i in range(1, len(pts)))

# â”€â”€ Ğ“ĞĞ›ĞĞ’ĞĞ˜Ğ™ Ğ¦Ğ˜ĞšĞ› â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_monitor():
    global anomaly_start_time
    cap = cv2.VideoCapture(0)
    users = load_database()
    print(f"[INFO] ĞšĞ°Ğ¼ĞµÑ€Ğ° Ğ°ĞºÑ‚Ğ¸Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ°. ĞŸÑ€Ğ¾Ñ„Ñ–Ğ»Ñ–Ğ² Ñƒ Ğ±Ğ°Ğ·Ñ–: {len(users)}")

    feature_buf = deque(maxlen=QUEUE_SIZE)
    pos_queue = deque(maxlen=QUEUE_SIZE)
    identified = None
    frame_idx = 0

    while cap.isOpened():
        ok, frame = cap.read()
        if not ok: break
        frame = cv2.flip(frame, 1)
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(rgb)

        label, color = "Scanning...", (255, 255, 0)

        if results.pose_landmarks:
            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            lm = results.pose_landmarks.landmark
            feats = extract_features(lm)
            if feats:
                feature_buf.append(feats)
                pos_queue.append(np.array([(lm[23].x+lm[24].x)/2, (lm[23].y+lm[24].y)/2]))

            # Ğ†Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ñ–ĞºĞ°Ñ†Ñ–Ñ
            if frame_idx % IDENTIFY_EVERY == 0 and len(feature_buf) >= 20:
                avg_vec = np.mean(list(feature_buf), axis=0).tolist()
                identified, sim = identify_person(avg_vec, users)

            if identified:
                label, color = f"OK: {identified['name']}", (0, 255, 0)
                
                # ĞĞ½Ğ°Ğ»Ñ–Ğ· Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ñ–Ğ¹
                active_anomaly = None
                if detect_zigzag(pos_queue): active_anomaly = "ZIGZAG"
                elif detect_stillness(pos_queue): active_anomaly = "STILLNESS"

                if active_anomaly:
                    if anomaly_start_time is None: 
                        anomaly_start_time = time.time()
                    
                    elapsed = time.time() - anomaly_start_time
                    label = f"CONFIRMING {active_anomaly}: {elapsed:.1f}s"
                    color = (0, 165, 255)

                    if elapsed >= ANOMALY_CONFIRM_TIME:
                        label = f"!!! ALARM {active_anomaly} !!!"
                        color = (0, 0, 255)
                        u_name = identified['name']
                        if time.time() - last_alerts.get(u_name, 0) > ALERT_COOLDOWN:
                            send_telegram_alert(u_name, identified['phone'], identified.get('chat_id'), active_anomaly)
                            last_alerts[u_name] = time.time()
                else:
                    anomaly_start_time = None
            else:
                label, color = "Unknown", (0, 165, 255)
        else:
            label, color = "No person", (128, 128, 128)
            anomaly_start_time = None

        cv2.putText(frame, label, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        cv2.imshow(f"MemoRescue Monitor", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'): break
        frame_idx += 1

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    run_monitor()

